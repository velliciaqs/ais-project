{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804ef49a-5b58-46ab-b41b-338f3786f045",
   "metadata": {},
   "source": [
    "1) Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba511a8a-0edc-414a-b59f-eced31a69419",
   "metadata": {},
   "source": [
    "Pengolahan ini menggunakan kernel ais-tt atau saat ini: pyspark3.3 ais2.8 untuk melakukan pengolahan data. Kernel ini dilengkapi dengan konfigurasi spark tambahan dan kredensial untuk Amazon Web Services (AWS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f89d32-4a0f-435f-bfae-d2df24537121",
   "metadata": {},
   "source": [
    " 2) Koneksi AIS Package dari AIS Task Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b38787-a6d1-4a06-8a1a-97a813b13ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git\n",
      "  Cloning https://read_aistt:****@code.officialstatistics.org/trade-task-team-phase-1/ais.git to /tmp/pip-req-build-oohd4rg0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "GITLAB_USER = \"read_aistt\"  #For use of members of AIS Task Team, read only access\n",
    "GITLAB_TOKEN = \"J1Kk8tArfyXB6dZvFcWW\"\n",
    "ais_package = f\"git+https://{GITLAB_USER}:{GITLAB_TOKEN}@code.officialstatistics.org/trade-task-team-phase-1/ais.git\"\n",
    "\n",
    "std_out = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\",ais_package], capture_output=True, text=True).stdout\n",
    "\n",
    "print(std_out) \n",
    "\n",
    "## Import modul\n",
    "from ais import functions as af"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cdb8a8-85f0-416c-9f94-a342c91072d4",
   "metadata": {},
   "source": [
    " 3) Import beberapa package yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d42eaef-8e43-4465-8b98-659aa10adc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd # membuat geodataframe\n",
    "import pandas as pd # membuat dataframe pandas\n",
    "import h3 # membuat dan membantu visualisasi index h3\n",
    "\n",
    "import matplotlib # plotting untuk visualisasi data\n",
    "import matplotlib.pyplot as plt # modul dalam matplotlib untuk membuat plot dan grafik\n",
    "from shapely.geometry import Polygon # kelas Shapely untuk membuat dan memanipulasi poligon\n",
    "from datetime import datetime # modul untuk manipulasi tanggal dan waktut Polygon # kelas Shapely untuk membuat dan memanipulasi poligon\n",
    "from datetime import datetime # modul untuk manipulasi tanggal dan waktu\n",
    "\n",
    "# SEDONA\n",
    "import sedona.sql # modul untuk menjalankan query SQL pada data spasial\n",
    "from sedona.register import SedonaRegistrator # alat untuk mendaftarkan Sedona ke Spark\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer \n",
    "# registrator untuk serialisasi objek spasial dengan Kryo\n",
    "# serializer untuk meningkatkan kinerja serialisasi\n",
    "\n",
    "# PYSPARK\n",
    "import pyspark.sql.functions as F # modul untuk fungsi SQL pada DataFrame\n",
    "import pyspark.sql.types as T # modul untuk tipe data SQL pada DataFrame\n",
    "from pyspark.sql import SparkSession  # kelas untuk membuat dan mengelola sesi Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f4af5-5e51-4026-8b35-86b16a0629db",
   "metadata": {},
   "source": [
    "4) Mengaktifkan Sesi Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ccd2f6-705a-4277-906a-bae8f0083e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('Emissions_Indonesia'). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config('spark.jars.packages'). \\\n",
    "    config(\"spark.sql.parquet.enableVectorizedReader\", \"false\").\\\n",
    "    getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495f798-bbb1-4282-a6a5-ba50d59676de",
   "metadata": {},
   "source": [
    " 5) Read Data AIS di AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c798b15-b1e6-4db7-9fa1-116f116a6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"s3a://ungp-ais-data-historical-backup/user_temp/\"\n",
    "save_path_unique = save_path + \"212112409/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e200eeb-1acd-414c-a191-abdd4c897083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read saved parquet\n",
    "data = spark.read.parquet(save_path_unique + \"ais-data-indonesia-2024_expanded.parquet\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09950f3-830c-48b6-94f1-7ea7a3e61f44",
   "metadata": {},
   "source": [
    "## Eksplorasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09a1906e-dbf0-49fd-b0b4-f4c6bf5e9b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720982034"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count all rows\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4a62ca-2b51-43c2-bb9f-9d4609fdf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample 1 data\n",
    "#data.show(n=1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f36cbaf-a573-4059-b207-5043dfbcb7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah jenis vessel_type yang berbeda: 26\n",
      "Daftar jenis vessel_type: ['Sailing', 'Tanker', 'Ships Not Party to Armed Conflict', 'Military', 'Towing', 'Reserved', 'SAR', 'Unknown', 'Other', 'UNAVAILABLE', 'Tug', 'Law Enforcement', 'Pleasure Craft', 'Passenger', 'Diving', 'Fishing', 'Port Tender', 'Spare', 'Medical Transport', 'WIG', 'Pilot', 'Dredging', 'Not Available', 'Cargo', 'Vessel With Anti-Pollution Equipment', 'HSC']\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan daftar nilai unik dari vessel_type\n",
    "unique_vessel_types = data.select('vessel_type').distinct().collect()\n",
    "\n",
    "# Menampilkan jumlah jenis vessel_type yang berbeda\n",
    "unique_vessel_type_count = len(unique_vessel_types)\n",
    "print(f\"Jumlah jenis vessel_type yang berbeda: {unique_vessel_type_count}\")\n",
    "\n",
    "# Menampilkan daftar vessel_type\n",
    "vessel_type_list = [row['vessel_type'] for row in unique_vessel_types]\n",
    "print(\"Daftar jenis vessel_type:\", vessel_type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1543de-e7af-4ef4-9468-605b62581186",
   "metadata": {},
   "source": [
    "## Mencocokkan record AIS dan IHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52e25e75-4fa6-4e14-8d9c-53a19b6c4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk melakukan pencocokan nama kapal AIS dan IHS\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "## Fungsi untuk mendapatkan nilai Cosine\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "## Fungsi untuk mengubah text menjadi vektor sebelum menghitung nilai cosine\n",
    "def text_to_vector(text):\n",
    "    text = str(text)\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "## Fungsi untuk melakukan perbandingan dua nama kapal dengan cosine similarity\n",
    "def compare_vessel_name(name_1, name_2):\n",
    "    vector1 = text_to_vector(name_1)\n",
    "    vector2 = text_to_vector(name_2)\n",
    "\n",
    "    cosine_result = get_cosine(vector1, vector2)\n",
    "    return cosine_result\n",
    "\n",
    "# Mengubah fungsi menjadi fungsi udf agar dapat dimanfaatkan dalam dataset pyspark\n",
    "compare = F.udf(lambda x,y:compare_vessel_name(x,y),T.DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cb6d1b7-21be-415d-9b7a-4edc73bd66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus record duplikat\n",
    "ais_data = data.distinct()\n",
    "\n",
    "# Ekstraksi data IHS\n",
    "specs = spark.read.load(\"s3a://ungp-ais-data-historical-backup/register/ShipData.CSV\",format=\"csv\",sep=\",\",inferSchema=\"true\",header=\"true\")\n",
    "specs = specs.withColumnRenamed(\"MaritimeMobileServiceIdentityMMSINumber\",\"mmsi_ihs\")\\\n",
    "                .withColumnRenamed(\"LRIMOShipNo\",\"imo_ihs\")\\\n",
    "                .withColumnRenamed(\"Draught\",\"SummerDraught\")\n",
    "\n",
    "# Penggabungan data AIS dan IHS\n",
    "## Record AIS yang Cocok Berdasaekan IMO\n",
    "imo_match = ais_data\\\n",
    "                    .join(specs, (ais_data.imo == specs.imo_ihs),how=\"inner\")\\\n",
    "                    .withColumn(\"matchBy\", F.lit(\"imo\"))\n",
    "\n",
    "## Record AIS yang Tidak Cocok Berdasarkan IMO\n",
    "ais_ihs_left = ais_data.join(specs, (ais_data.imo == specs.imo_ihs),how=\"left_anti\")\n",
    "\n",
    "## Record AIS yang Tidak Cocok Berdasarkan IMO dan cocok berdasarkan MMSI\n",
    "mmsi_match = ais_ihs_left.join(specs, (ais_ihs_left.mmsi == specs.mmsi_ihs),how=\"inner\")\n",
    "\n",
    "## Record AIS yang Tidak Cocok Berdasarkan IMO dan cocok berdasarkan MMSI dan Nama kapal\n",
    "vessel_name_check = mmsi_match.withColumn(\"similarity\", compare(F.col(\"vessel_name\"), F.col(\"ShipName\")))\n",
    "vessel_name_match = vessel_name_check.filter(F.col(\"similarity\")>=0.50)\\\n",
    "                                        .withColumn(\"imo\", F.col(\"imo_ihs\"))\\\n",
    "                                        .withColumn(\"matchBy\", F.lit(\"mmsi\"))\n",
    "\n",
    "## Penggabungan Record AIS yang cocok Berdasarkan IMO dan (MMSI dan Nama Kapal)\n",
    "match_record = imo_match.union(vessel_name_match.drop(F.col(\"similarity\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca731e-ef17-4d70-9057-212ccaf6e7e0",
   "metadata": {},
   "source": [
    " ## Jumlah record per tahap preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20195512-00f1-4437-8693-c53dd99101b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Jumlah record|          Keterangan|\n",
      "+-------------+--------------------+\n",
      "|    720982034|Record AIS Indone...|\n",
      "|    720982034|Penghapusan duplikat|\n",
      "|    612394139|Pencocokan dengan...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming match_record contains some textual data, we sanitize it first\n",
    "match_record = match_record.filter(match_record[\"vessel_name\"].isNotNull())  # Filter out null values\n",
    "match_record = match_record.withColumn(\"vessel_name\", match_record[\"vessel_name\"].cast(\"string\"))  # Cast to string if necessary\n",
    "\n",
    "# Then try counting it again\n",
    "table_filter = spark.createDataFrame([\n",
    "    {\"Keterangan\": \"Record AIS Indonesia Tahun 2019\", \"Jumlah record\": data.count()},\n",
    "    {\"Keterangan\": \"Penghapusan duplikat\", \"Jumlah record\": ais_data.count()},\n",
    "    {\"Keterangan\": \"Pencocokan dengan database IHS\", \"Jumlah record\": match_record.count()}\n",
    "])\n",
    "\n",
    "table_filter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8af571-9ed8-450f-a4ee-5e6617ff355c",
   "metadata": {},
   "source": [
    "## Jumlah record berdasarkan jenis kecocokan dengan data IHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a18ef11-f2a3-4bd3-a421-e7a521c0f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Jumlah record|          Keterangan|\n",
      "+-------------+--------------------+\n",
      "|    567960767|    Cocok dengan IMO|\n",
      "|     55008288|   Cocok dengan MMSI|\n",
      "|     44433393|Cocok dengan Nama...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " table_match = spark.createDataFrame([\n",
    "    {\"Jumlah record\": imo_match.count(), \"Keterangan\": \"Cocok dengan IMO\"},\n",
    "    {\"Jumlah record\": mmsi_match.count(), \"Keterangan\": \"Cocok dengan MMSI\"},\n",
    "    {\"Jumlah record\": vessel_name_match.count(), \"Keterangan\": \"Cocok dengan Nama Kapal\"}\n",
    "])\n",
    "table_match.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4bba1-be3a-49cc-a204-b6879125cc70",
   "metadata": {},
   "source": [
    "## Jumlah kapal berdasarkan kecocokan dengan data IHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc7a0bab-d1cf-4052-975d-ab163cb19232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Jumlah record|          Keterangan|\n",
      "+-------------+--------------------+\n",
      "|        28889|    Cocok dengan IMO|\n",
      "|         5546|Cocok dengan MMSI...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_vessel = spark.createDataFrame([\n",
    "    {\"Jumlah record\": imo_match.dropDuplicates([\"imo\"]).count(), \"Keterangan\": \"Cocok dengan IMO\"},\n",
    "    {\"Jumlah record\": vessel_name_match.dropDuplicates([\"imo\"]).count(), \"Keterangan\": \"Cocok dengan MMSI dan Nama Kapal\"}\n",
    "])\n",
    "table_vessel.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22044b3d-2d3d-4aac-8183-f4ee47f29900",
   "metadata": {},
   "source": [
    "## Menghitung durasi antar pesan AIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5c84cf3-4e8b-4c4a-93f5-6d214fc5581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung durasi\n",
    "def count_freq(dfspark):\n",
    "    df = (\n",
    "      dfspark\n",
    "      .selectExpr(\n",
    "        \"*\"\n",
    "      )\n",
    "      .withColumn(\"previous_freq\",F.expr(f\"LAG(dt_pos_utc) OVER (PARTITION BY imo ORDER BY dt_pos_utc ASC) as previous_freq\"))\n",
    "      .withColumn(\"previous_h3\",F.expr(f\"LAG(H3_int_index_7) OVER (PARTITION BY imo ORDER BY dt_pos_utc ASC) as previous_h3\"))\n",
    "      .withColumn(\"freq\", F.expr(f\"(unix_timestamp(dt_pos_utc)-unix_timestamp(previous_freq))/3600 as freq\"))\n",
    "      .selectExpr(\n",
    "        \"*\"\n",
    "      )\n",
    "\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bc6f6f1-ba12-4d98-a1af-e4c8ffba4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = count_freq(match_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f27dddb-fd3c-40c3-8a3f-3b5bbe26b979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612394139"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7abb43e5-5193-4afe-8950-85851ee722a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show(n=1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab004586-45b1-42ec-b934-5896c092ebf7",
   "metadata": {},
   "source": [
    "## SAVING FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5598a954-7ea6-4857-8b1f-71c14cef5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus kolom duplikat\n",
    "df = df.drop(\"callsign\")\n",
    "df = df.drop(\"callsign_duplicate\")\n",
    "\n",
    "# Menyimpan DataFrame sebagai file Parquet\n",
    "df.write.option(\"header\", True).mode(\"overwrite\").parquet(save_path_unique + \"ais-ihs-indonesia-2024.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934e1dc-b136-4008-b03c-c0aeb20a72a7",
   "metadata": {},
   "source": [
    " ## Stop Sesi Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "409a840d-7490-4334-9d5c-8feb9c7d04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while attempting Spark job cancellation when interrupting the kernel: 'NoneType' object has no attribute 'sc'\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60c349-8b6e-477c-b218-73a28a23b80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430390e0-03bc-4770-8e98-bc9182626023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark3.3 ais2.8 (prev ais-tt-dev)",
   "language": "python3",
   "name": "ais-tt-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
